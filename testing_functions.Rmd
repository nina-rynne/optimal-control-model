---
title: "testing_functions"
output: html_document
date: "2025-03-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}

# Load required libraries
library(dplyr)
library(tidyr)
library(readr)
library(here)
library(testthat)
library(ggplot2)  # For plotting (if needed)

```

```{r data_preparation_test, eval=FALSE, include=FALSE}

# Source the data preparation functions
source(here::here("src", "data_preparation.R"))

# Test import_ssp_emissions function
# ------------------------------------
cat("Testing import_ssp_emissions function...\n")

# Import emissions data - just pass the filename, path handling is in the import function
emissions_imported <- import_ssp_emissions("emissions.csv")
cat("Imported emissions data dimensions:", dim(emissions_imported)[1], "rows,", 
    dim(emissions_imported)[2], "columns\n")

# Display sample of the imported emissions data
cat("\nSample of imported emissions data:\n")
print(head(emissions_imported, 3))

# Test import_ssp_economic function
# ------------------------------------
cat("\nTesting import_ssp_economic function...\n")

# Import economic data - just pass the filename, path handling is in the import function
economic_imported <- import_ssp_economic("gwp.csv")
cat("Imported economic data dimensions:", dim(economic_imported)[1], "rows,", 
    dim(economic_imported)[2], "columns\n")

# Display sample of the imported economic data
cat("\nSample of imported economic data:\n")
print(head(economic_imported, 3))

# Test interpolate_ssp_emissions function
# ------------------------------------
cat("\nTesting interpolate_ssp_emissions function...\n")

# Test with annual time step
emissions_df <- interpolate_ssp_emissions(
  emissions_df = emissions_imported,
  dt = 1,
  start_year = 2020,
  end_year = 2100
)
cat("Interpolated emissions data dimensions:", dim(emissions_df)[1], "rows,", 
    dim(emissions_df)[2], "columns\n")

# Test interpolate_ssp_economic function
# ------------------------------------
cat("\nTesting interpolate_ssp_economic function...\n")

# Test with annual time step
economic_df <- interpolate_ssp_economic(
  economic_df = economic_imported,
  dt = 1,
  start_year = 2020,
  end_year = 2100
)
cat("Interpolated economic data dimensions:", dim(economic_df)[1], "rows,", 
    dim(economic_df)[2], "columns\n")

cat("\nTest script completed.\n")

```

```{r experimental_design_test, eval=FALSE, include=FALSE}
# This script tests the functionality of the generate_lhs_samples function
# from the experimental_design.R script in the src directory

# Source the experimental_design.R script from the src directory
source("src/experimental_design.R")

# Run the function with default parameters and display the results
cat("\n=== SAMPLE OUTPUT WITH DEFAULT PARAMETERS ===\n")
parameter_df <- generate_lhs_samples()
cat("\nFirst 10 rows of the generated samples:\n")
print(head(parameter_df, 10))

cat("\nSummary statistics of the generated samples:\n")
print(summary(parameter_df))

# Define tests
test_that("generate_lhs_samples produces expected outputs", {
  
  # Test 1: Basic execution with default parameters
  cat("Test 1: Basic execution with default parameters\n")
  result_default <- generate_lhs_samples()
  
  # Check result structure
  expect_true(is.data.frame(result_default))
  expect_equal(nrow(result_default), 50)  # Default n_samples is 50
  expect_equal(ncol(result_default), 5)   # There should be 5 parameters
  
  # Check parameter names
  expected_params <- c("tcre", "cost_mitig_unit", "cost_remov_unit", "econ_dam_pct", "disc_rate")
  expect_equal(names(result_default), expected_params)
  
  # Test 2: Parameter values are within expected ranges
  cat("Test 2: Parameter values are within expected ranges\n")
  expect_true(all(result_default$tcre >= 0.0027 & result_default$tcre <= 0.0063))
  expect_true(all(result_default$cost_mitig >= 200 & result_default$cost_mitig <= 1000))
  expect_true(all(result_default$cost_remov >= 5 & result_default$cost_remov <= 1000))
  expect_true(all(result_default$econ_dam_pct >= 0.05 & result_default$econ_dam_pct <= 0.2))
  expect_true(all(result_default$disc_rate >= 0.01 & result_default$disc_rate <= 0.05))
  
  # Test 3: Reproducibility with seed
  cat("Test 3: Reproducibility with seed\n")
  result_seed1 <- generate_lhs_samples(seed = 123)
  result_seed2 <- generate_lhs_samples(seed = 123)
  expect_equal(result_seed1, result_seed2)
  
  # Test 4: Different sampling methods
  cat("Test 4: Different sampling methods\n")
  result_optimum <- generate_lhs_samples(sampling_method = "optimum")
  result_genetic <- generate_lhs_samples(sampling_method = "genetic")
  
  expect_true(is.data.frame(result_optimum))
  expect_true(is.data.frame(result_genetic))
  expect_equal(nrow(result_optimum), 50)
  expect_equal(nrow(result_genetic), 50)
  
  # Test 5: Return raw option
  cat("Test 5: Return raw option\n")
  result_raw <- generate_lhs_samples(return_raw = TRUE)
  
  expect_true(is.list(result_raw))
  expect_equal(length(result_raw), 2)
  expect_true("raw_samples" %in% names(result_raw))
  expect_true("scaled_samples" %in% names(result_raw))
  expect_equal(dim(result_raw$raw_samples), c(50, 5))
  expect_equal(dim(result_raw$scaled_samples), c(50, 5))
  
  # Test 6: Custom sample size
  cat("Test 6: Custom sample size\n")
  result_custom <- generate_lhs_samples(n_samples = 100)
  
  expect_equal(nrow(result_custom), 100)
  
  # Test 7: Error handling - invalid sample size
  cat("Test 7: Error handling - invalid sample size\n")
  expect_error(generate_lhs_samples(n_samples = -10))
  expect_error(generate_lhs_samples(n_samples = "invalid"))
  
  # Test 8: Error handling - invalid sampling method
  cat("Test 8: Error handling - invalid sampling method\n")
  expect_error(generate_lhs_samples(sampling_method = "invalid_method"))
  
  # Test 9: Error handling - invalid return_raw
  cat("Test 9: Error handling - invalid return_raw\n")
  expect_error(generate_lhs_samples(return_raw = "yes"))
})

# Run distribution tests
test_that("LHS generates well-distributed samples", {
  
  # Test 10: Distribution properties
  cat("Test 10: Distribution properties\n")
  set.seed(42)
  samples <- generate_lhs_samples(n_samples = 1000)
  
  # Check that samples are relatively uniformly distributed (using quartiles)
  for (param in names(samples)) {
    quartiles <- quantile(samples[[param]], probs = c(0.25, 0.5, 0.75))
    range_size <- max(samples[[param]]) - min(samples[[param]])
    
    # Check if quartiles are roughly where they should be
    expect_true(abs(quartiles[1] - (min(samples[[param]]) + 0.25 * range_size)) < 0.1 * range_size)
    expect_true(abs(quartiles[2] - (min(samples[[param]]) + 0.5 * range_size)) < 0.1 * range_size)
    expect_true(abs(quartiles[3] - (min(samples[[param]]) + 0.75 * range_size)) < 0.1 * range_size)
  }
})

# Run performance tests
test_that("Function performs within acceptable limits", {
  
  # Test 11: Performance test
  cat("Test 11: Performance test\n")
  start_time <- Sys.time()
  generate_lhs_samples(n_samples = 1000)
  end_time <- Sys.time()
  
  # Function should run in less than 2 seconds for 1000 samples
  execution_time <- as.numeric(difftime(end_time, start_time, units = "secs"))
  expect_true(execution_time < 2)
})

# Summary of test results
cat("\nAll tests completed.\n")


```

```{r model_parameters_test, eval=FALSE, include=FALSE}

#' @title Test Script for Model Parameters Functions
#' @description 
#' This script tests the functionality of the model_parameters.R script, which contains
#' functions for loading, managing, and manipulating parameters for climate models.
#' 
#' It runs a series of tests on the functions:
#' - get_fixed_parameters()
#' - add_fixed_parameters()
#'

# Source the model parameters script from the src folder
source(here::here("src", "model_parameters.R"))

# Define the path to the actual parameter file
param_file <- here::here("parameter_details.yml")

# Function to print formatted section headers
print_section <- function(text) {
  cat("\n", paste(rep("=", 80), collapse = ""), "\n")
  cat(" ", text, "\n")
  cat(paste(rep("=", 80), collapse = ""), "\n\n")
}

# Begin testing
print_section("TESTING MODEL PARAMETERS FUNCTIONS")

# Test 1: Check if get_fixed_parameters loads correctly
test_that("get_fixed_parameters loads parameters correctly", {
  # Call function with the actual parameter file
  params <- get_fixed_parameters(config_file = param_file)
  
  # Check if the function returns a list
  expect_true(is.list(params))
  
  # Check if specific parameters are present with correct values
  expect_equal(params$clim_temp_init, 1.2)
  expect_equal(params$exp_mitig, 2)
  
  # Print success message
  cat("✓ get_fixed_parameters loads\n")
})

# Test 2: removed

# Test 3: removed

# Test 4: Error handling for missing file
test_that("get_fixed_parameters handles missing file gracefully", {
  # Try to load a non-existent file
  expect_error(
    get_fixed_parameters(config_file = "non_existent_file.yml"),
    "Configuration file not found"
  )
  
  cat("✓ get_fixed_parameters handles missing file gracefully\n")
})

# Test 5: Test add_fixed_parameters function with default_samples
test_that("add_fixed_parameters combines variable and fixed parameters", {
  # Add fixed parameters to default_samples
  combined_params <- add_fixed_parameters(
    param_df = parameter_df,
    config_file = param_file
  )
  
  # Check if result is a dataframe
  expect_true(is.data.frame(combined_params))
  
  # Check if both variable and fixed parameters are present
  # Using actual column names from default_samples
  expect_true("tcre" %in% names(combined_params))
  expect_true("cost_mitig_unit" %in% names(combined_params))
  expect_true("clim_temp_init" %in% names(combined_params))
  
  # Check if the number of rows matches the input
  expect_equal(nrow(combined_params), nrow(parameter_df))
  
  cat("✓ add_fixed_parameters successfully combines variable and fixed parameters\n")
})

# Test 6: Test different append positions
test_that("add_fixed_parameters respects append_position", {
  # Test "start" position
  start_params <- add_fixed_parameters(
    param_df = parameter_df,
    append_position = "start",
    config_file = param_file
  )
  
  # Check if the fixed parameters come first
  first_col <- names(start_params)[1]
  expect_true(first_col != "tcre")
  
  # Test "alphabetical" position
  alpha_params <- add_fixed_parameters(
    param_df = parameter_df,
    append_position = "alphabetical",
    config_file = param_file
  )
  
  # Columns should be in alphabetical order
  expect_equal(names(alpha_params), sort(names(alpha_params)))
  
  cat("✓ add_fixed_parameters respects different append_position values\n")
})

# Test 7: Parameter exclusion
test_that("add_fixed_parameters can exclude specified parameters", {
  # Exclude some parameters
  excluded_params <- add_fixed_parameters(
    param_df = parameter_df,
    config_file = param_file,
    exclude_params = c("temp_init", "exp_mitig")
  )
  
  # Check if excluded parameters are actually excluded
  expect_false("temp_init" %in% names(excluded_params))
  expect_true("co2_conc_preind" %in% names(excluded_params))
  
  cat("✓ add_fixed_parameters can exclude specified parameters\n")
})

# Test 8: Check metadata attributes
test_that("add_fixed_parameters adds appropriate metadata", {
  result <- add_fixed_parameters(
    param_df = parameter_df,
    config_file = param_file
  )
  
  # Check if metadata attribute exists
  expect_true(!is.null(attr(result, "parameter_source")))
  
  # Check if metadata contains expected elements
  metadata <- attr(result, "parameter_source")
  expect_true("variable_params" %in% names(metadata))
  expect_true("fixed_params" %in% names(metadata))
  
  cat("✓ add_fixed_parameters adds appropriate metadata attributes\n")
})

# Test 9: Just run get_fixed_parameters with default options and print the result
cat("Test 9: Running get_fixed_parameters() with default options:\n")
parameter_df <- get_fixed_parameters()
cat("\nStructure of the returned parameters:\n")
str(parameter_df)
cat("\nFirst few parameters:\n")
if (length(parameter_df) > 0) {
  head_params <- head(parameter_df, 5)
  for (name in names(head_params)) {
    cat(sprintf("  %s: %s\n", name, as.character(head_params[[name]])))
  }
} else {
  cat("  No parameters found\n")
}

# Test 10: Run add_fixed_parameters with default options and print the result
cat("\nTest 10: Running add_fixed_parameters() with default options:\n")
parameter_df <- add_fixed_parameters(parameter_df)
cat("\nStructure of the returned dataframe:\n")
str(parameter_df)
cat("\nColumn names in the combined dataframe:\n")
cat(paste(names(parameter_df), collapse = ", "), "\n")
cat("\nFirst few rows of the combined dataframe:\n")
print(head(combined_default, 3))

cat("\n✓ Default function outputs displayed for inspection\n")

print_section("ALL TESTS COMPLETED")

# Summarize results
cat("Test Summary:\n")
cat("- 8 tests run\n")
cat("- All functions behave as expected\n")
cat("- get_fixed_parameters and add_fixed_parameters work correctly with valid inputs\n")
cat("- Error handling for invalid inputs is appropriate\n\n")

```

```{r optimal_control_test, eval=FALSE, include=FALSE}

#' @title Run Optimal Control Simulations for Climate Temperature Overshoot
#' @description
#' This script demonstrates how to run optimal control simulations using the
#' framework with Latin Hypercube Sampling of uncertain parameters.
#'
#' @author Nina Rynne
#' @project Optimal Control of Temperature Overshoot
#' @date March 2025
#' @license MIT
#' @version 0.1.0
#'

# Source required function scripts
source(here::here("src", "data_preparation.R"))      # For data loading and preparation
source(here::here("src", "experimental_design.R"))   # For LHS parameter sampling
source(here::here("src", "model_parameters.R"))      # For parameter management
source(here::here("src", "optimal_control.R"))       # For optimal control simulations

# Set random seed for reproducibility
set.seed(42)

# ---- 1. Import and prepare emissions data ----
# Load SSP3-7.0 emissions data
emissions_data <- import_ssp_emissions(
  file_name = "emissions.csv",
  scenarios = "SSP3-Baseline",
  variables = "CO2 emissions"
)

# Interpolate emissions to annual time steps
emissions_interpolated <- interpolate_ssp_emissions(
  emissions_df = emissions_data,
  dt = 1,
  start_year = 2020,
  end_year = 2100
)

# ---- 2. Import and prepare economic data ----
# Load economic data for damage calculation (optional)
economic_data <- import_ssp_economic(
  file_name = "gwp.csv",
  scenarios = "SSP3-Baseline",
  variables = "GDP"
)

# Interpolate economic data to annual time steps
economic_interpolated <- interpolate_ssp_economic(
  economic_df = economic_data,
  dt = 1,
  start_year = 2020,
  end_year = 2100
)

# ---- 3. Generate parameter sets using Latin Hypercube Sampling ----
# Generate 50 parameter sets using optimum LHS
lhs_samples <- generate_lhs_samples(
  n_samples = 50,
  seed = 42,
  sampling_method = "optimum"
)

# Add fixed parameters to create complete parameter sets
parameter_sets <- add_fixed_parameters(
  param_df = lhs_samples,
  append_position = "end"
)

# Print the first few parameter sets to verify
cat("Generated", nrow(parameter_sets), "parameter sets\n")
print(head(parameter_sets, 3))

# ---- 4. Run a single simulation test ----
# Extract first parameter set for testing
test_params <- parameter_sets[1, ]

# Initialize a log file for the test run
test_log <- init_log_file("test_run")
cat("Running test simulation with first parameter set\n")

# Run test simulation using shooting method
test_result <- run_single_simulation(
  emissions_df = emissions_interpolated,
  parameters = test_params,
  gwp_df = economic_interpolated,
  method = "shooting",
  verbose = TRUE,
  log_file = test_log
)

# Check test result
cat("Test simulation completed\n")
cat("Final cumulative emissions:", 
    test_result$Cumulative_Emissions[nrow(test_result)], "GtCO2\n")
cat("Maximum temperature:", max(test_result$Temp_Anom_C), "°C\n")

# ---- 5. Run multiple simulations (comment out for initial testing) ----
# Uncomment to run multiple simulations

# cat("Running simulations for all parameter sets\n")
# 
# # Run simulations for all parameter sets
# all_results <- run_multiple_simulations(
#   emissions_df = emissions_interpolated,
#   parameter_sets = parameter_sets,
#   gwp_df = economic_interpolated,
#   method = "shooting",
#   parallel = FALSE,  # Set to TRUE to use parallel processing
#   save_results = TRUE
# )
# 
# # Print summary of results
# cat("Completed", all_results$n_success, "successful simulations out of", 
#     nrow(parameter_sets), "total\n")
# 
# # Examine distribution of key metrics
# if (all_results$n_success > 0) {
#   summary_stats <- summary(all_results$summary)
#   print(summary_stats)
# }

# ---- 6. Plot results from test simulation ----
# Create a basic plot of temperature trajectories
ggplot(test_result) +
  geom_line(aes(x = Year, y = Temp_Anom_C), color = "blue", linewidth = 0.8) +
  geom_line(aes(x = Year, y = Temp_Anom_Baseline_C), color = "black", linetype = "dashed") +
  geom_hline(yintercept = 1.5, color = "red", linetype = "dotted", linewidth = 0.8) +
  labs(title = "Temperature Trajectories",
       subtitle = "Blue = Optimal, Black = Baseline, Red = 1.5°C threshold",
       x = "Year", 
       y = "Temperature (°C)") +
  theme_minimal()

# Save the plot
ggsave(here::here("figs", "plots", paste0("temperature_trajectory_", 
                                  format(Sys.time(), "%Y%m%d_%H%M%S"), ".png")),
       width = 8, height = 6)

cat("Simulation complete. Results saved to the results and plots directories.\n")


```

```{r test_shooting_method, eval=FALSE, include=FALSE}



```


```{r pull_vectors, eval=FALSE, include=FALSE}

# Assuming your list is called "my_list"
# This will extract a vector from a nested list and save it as a CSV

# Define the path to access the specific vector
# For example, if your vector is in my_list$sublist$subsublist$vector_name
main_list <- "oc_solution"
first_level <- "run_20250429_133128_1"
vector_name <- "baseline_annual_emissions"

# Extract the vector
extracted_vector <- main_list[[first_level]][[vector_name]]

# Create a data frame from the vector
# This handles both named vectors and unnamed vectors
if(!is.null(names(extracted_vector))) {
  df <- data.frame(
    name = names(extracted_vector),
    value = extracted_vector,
    stringsAsFactors = FALSE
  )
} else {
  df <- data.frame(value = extracted_vector)
}

# Define output path and filename
output_file <- "test/baseline_annual_emissions.csv"

# Write to CSV
write.csv(df, file = output_file, row.names = FALSE)

# Confirmation message
cat("Vector", vector_name, "has been saved to", output_file, "\n")


```

```{r test_pull_vectors, eval=FALSE, include=FALSE}

# Set the list and element names
main_list <- "oc_solution"
first_level <- "run_20250429_133128_1"
vector_name <- "temperature_anomaly"

# Load the list if it's not already in the environment
if(!exists(main_list)) {
  # If the list is stored in an .RData file, load it
  # load("path/to/your/list.RData")
  # Or if it's stored as an RDS file
  # oc_solution <- readRDS("path/to/your/list.rds")
}

# Get the list object
my_list <- get(main_list)

# Create the test folder if it doesn't exist
dir.create("test", showWarnings = FALSE)

# Debug: Check if the first level exists
if(first_level %in% names(my_list)) {
  # Debug: Print structure of the first level to see available elements
  cat("Structure of first level:\n")
  print(names(my_list[[first_level]]))
  
  # Check if the vector exists directly in the first level
  if(vector_name %in% names(my_list[[first_level]])) {
    extracted_vector <- my_list[[first_level]][[vector_name]]
    
    # Create a data frame from the vector
    df <- data.frame(value = extracted_vector)
    
    # Define output file with the test folder
    output_file <- file.path("test", paste0(vector_name, ".csv"))
    
    # Write to CSV
    write.csv(df, file = output_file, row.names = FALSE)
    cat("Vector", vector_name, "has been saved to", output_file, "\n")
  } else {
    cat("Vector", vector_name, "not found in", first_level, "\n")
    cat("Available vectors in this level:\n")
    print(names(my_list[[first_level]]))
  }
} else {
  cat("First level", first_level, "not found in", main_list, "\n")
  cat("Available first levels:\n")
  print(names(my_list))
}

```

```{r cost_surface_plot, eval=FALSE, include=FALSE}

# Define the formula as a function
cost_function <- function(t, x) {
  ((x^2) * 0.3) * (exp(-discount_rate * (t - t_0)))
}

# Create the cost matrix directly using outer
cost_matrix <- outer(time_steps, units, cost_function)

# Now use persp without transpose
persp(x = time_steps, 
      y = units, 
      z = cost_matrix,  # No transpose needed with outer()
      theta = 30, phi = 20,
      col = "lightblue",
      xlab = "Time Step", 
      ylab = "Number of Units", 
      zlab = "Cost",
      main = "Cost Over Time and Units",
      ticktype = "detailed")


```


```{r run_dynamic_programming}

source(here::here("src", "dynamic_programming.R"))

# Run dynamic programming
dp_result <- climate_dynamic_programming(
  parameter_df = parameter_df,
  emissions_df = emissions_df,
  economic_df = economic_df,
  scenario = scenario,
  state_grid_size = 100,  # Increase for more precision
  control_grid_size = 25  # Increase for more precise controls
)

# Create visualization
dp_dashboard <- create_dp_dashboard(dp_result)

```

```{r run_nlp}

# Source the NLP implementation
source(here::here("src", "non_linear_programming.R"))

# Run the optimized non-linear programming 
nlp_result <- climate_nonlinear_programming(
  parameter_df = parameter_df,
  emissions_df = emissions_df,
  economic_df = economic_df,
  scenario = scenario,
  max_iterations = 300,  # Lower iterations for faster convergence
  verbose = TRUE
)

# Create visualization
nlp_dashboard <- create_nlp_dashboard(nlp_result)

```

```{r run_slsqp}

# Source the SLSQP implementation
source(here::here("src", "non_linear_programming.R"))

# Run the optimized non-linear programming 
nlp_result <- climate_slsqp_programming(
  parameter_df = parameter_df,
  emissions_df = emissions_df,
  economic_df = economic_df,
  scenario = scenario,
  max_iterations = 300,  # Lower iterations for faster convergence
  verbose = TRUE
)

# Create visualization
slsqp_dashboard <- create_nlp_dashboard(slsqp_result)

```



```{r not_complete_code, eval=FALSE, include=FALSE}


```

